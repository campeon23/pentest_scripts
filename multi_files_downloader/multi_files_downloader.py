#!/usr/bin/env python

import requests
import os
import argparse
from urllib.parse import urlsplit

'''
        To run the script, run it from the terminal and provide the URLs as arguments separated by space. Here is an example:

        python multi_files_downloader.py -u "https://www.example.com/file1.jpg" "https://www.example.com/file2.jpg"
        
        or

        python multi_files_downloader.py --url "https://www.example.com/file1.jpg" "https://www.example.com/file2.jpg"
'''


def download(url):
    """
    Downloads the content from the provided URL and saves it locally as a file.

    Parameters:
    url (str): The URL of the file to download.
    """

    response = requests.get(url)

    # split the url to get the filename, we are taking last part of the url as filename
    filename = os.path.basename(urlsplit(url).path)

    # write the content into the file
    with open(filename, 'wb') as out_file:
        out_file.write(response.content)


def main(urls):
    """
    Main function to download files from provided list of urls.

    Parameters:
    urls (list of str): The URLs of files to download.
    """

    for url in urls:
        download(url)


if __name__ == "__main__":
    # Create argument parser to handle command line arguments
    parser = argparse.ArgumentParser(
        description="Download files from provided URLs.")
    parser.add_argument("-u", "--urls", nargs="+",
                        help="List of URLs separated by space.", required=True)

    args = parser.parse_args()

    main(args.url)
