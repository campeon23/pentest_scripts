#!/usr/bin/env python
import argparse
import requests

'''
        Run the script by providing the target_url and wordlist arguments in the following format:   
        
        python hidden_files_crawler.py --target_url google.com --wordlist ./subdomains-wodlist.txt.
        
        If a subdomain is discovered, it will be printed to the terminal.
'''


def send_request(url):
    """
    Function to send a GET request to the provided URL.
    """
    try:
        return requests.get('http://' + url)
    except requests.exceptions.ConnectionError:
        # Uncomment the following line if you want to print the error
        # print('Site does not exist or is currently down: ' + err)
        pass


def discover_files_and_dirs(target_url, wordlist_file):
    """
    Function to discover files and directories from the provided wordlist file.
    """
    with open(wordlist_file, 'r') as wordlist:
        for line in wordlist:
            test_url = target_url + '/' + line.strip('\r\n')
            response = send_request(test_url)
            if response:
                print('[+] Discovered URL --> ' + test_url)


def main(target_url, wordlist_file):
    """
    The main function that runs the program.
    """
    discover_files_and_dirs(target_url, wordlist_file)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description='File and Directory Discoverer')
    parser.add_argument("-t", "--target-url", dest="target_url", type=str,
                        required=True, help="The target URL")
    parser.add_argument("-w", "--wordlist-file", dest="wordlist_file", type=str,
                        required=True, help="Path to the wordlist file")

    args = parser.parse_args()

    main(args.target_url, args.wordlist_file)
